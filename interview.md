# Interview

- [ ] 自我介绍
- [ ] 业务介绍
- [ ] 业务亮点
  - 高可用、高可靠、节约资源
- [ ] 印象深刻的问题
  - 多个程序并发下载并使用同一张图片，尽量避免重复下载。判断图片是否存在，存在就使用。有两种情况会出错，一种是其他协程下载未完成就开始使用，一种是下载过程中其他协程开始下载，使用时图片不完整。解决方式是先下载成别名再mv。后来同样的策略用在共享存储上，由于共享存储的机制，该策略无法解决问题，改为划分文件夹。然后mq抖动时再次出现该问题，由于mq重复消费又导致了多个线程的并发读写，后来通过在文件夹后加随机字符串的方式解决。
- [ ] 为什么重构
  - go上手难度低
  - 自动的内存管理
  - defer可以保证释放
  - 部署简单
  - 支持并发
  - 开发工具完备
- [ ] 觉得之前工作中的服务还可以怎样优化（代码、架构、稳定性、流程）
- [ ] 做过那些比较厉害的事
- [ ] 怎么读源码，读过哪些源码，比较惊艳的代码
- [ ] 觉得自己有哪些不足，如何提升
- [ ] 未来的规划
<!-- - [ ] 高并发
  - `10(同时过车)*50(子任务)*500服务` 25w-30w并发
  - 分布式集群：对系统进行了垂直拆分，请求会根据功能转发到不同的微服务；模块解耦方便修改和隔离
  - 消息队列 削峰填谷
  - 扩容 垂直扩容（一般是升级硬件，成本高，收益一般）水平扩容（通过增加节点数量）
  - 限流 
  - 服务降级与熔断
  - 分库分表
  - 缓存 车辆信息、先导结果、中间结果写缓存
  - 负载均衡 -->
- 经验教训
  - 记得问不足之处
  - 设计的东西不用说太多，要对应岗位职责
  - 用的少的地方简单说用到的地方，不要说用的少，容易堵上话题

## Linux

- [x] top
  实时监控，显示整体性能信息和正在运行的进程相关信息。
  - 显示系统的运行时间、平均负载（1，5，15分钟）
  - 当前运行的进程线程数
  - 总体CPU使用率和各个核心的使用情况
    - us 用户空间、sy 系统空间、ni 改变过优先级的进程消耗掉的CPU时间、id 空闲、wa 等待、hi 硬中断、si 软中断
  - 内存和交换区的总量/可用/缓存情况，内存不够时会把暂时不用的放在交换区，交换区升高说明真不够用了。
  - 进程信息
    - PID 进程id、USER 用户、PR 优先级、NI nice值、VIRT 虚拟内存总量、RES 实际内存、SHR 共享内存、S 进程状态
- [ ] 服务器负载高怎么排查
  - 可能是CPU负载高，检查是否有某个进程占用了大量CPU资源
  - 检查内存使用率
  - 检查I/O负载和网络带宽负载
- [x] 软链接硬链接区别
  - 硬链接允许一个文件有多个有效路径名，防止误删
  - 软连接类似快捷方式，是一个特殊的文件，访问的时候自动替换为对应的文件路径
- [ ] 进程组
  - ps ajx查看进程组，kill的时候用负值可以杀死进程组，但是使用负值要小心
- [ ] fork
  - fork复制整个进程，但是只启用它所在的执行路径，如果执行路径fork后有创建的线程，子进程创建线程。fork之前创建的则会启动当前线程
- [ ] 怎么排查内存泄漏
  1. 使用vmstat查询内存变化情况。swap 交换区内存；buff 用作缓冲区的内存；cache 用作缓存的内存
  2. 使用memleak检查是否发生了泄露并根据调用栈定位内存的分配位置，从而释放不再使用的内存。
- [ ] git冲突是怎么产生的
  - 已经提交的分支的相同文件相同位置的不同操作进行了合并

## 计算机基础

- [ ] LRU、LFU、LRU-K
  - LRU基于访问时间、LFU基于访问次数、LRU-K是二者的结合，LRU可以认为是LRU-1
  - 相比于LRU，LRU-K要多维护一个队列，用于记录所有缓存数据被访问的历史，访问次数达到K时才放入缓存，需要淘汰时淘汰低K次访问距离当前时间最大的数据。实际一般用LRU-2。
  - LFU命中率一般好于LRU，但是需要记录所有数据的访问记录，内存消耗大，需要基于引用计数排序，性能消耗高，LRU-K基本上也是。
- [ ] 进程、线程、协程
  - 进程是操作系统资源分配的基本单位；线程是任务调度和执行的基本单位；协程是用户态的轻量级线程，由用户调度
  - 进程有独立的地址空间，切换开销大；线程有自己的堆栈和局部变量，但是没有独立地址空间，切换开销小；协程切换完全由程序控制，不需要内核调度，开销更小。
  - （协程有自己的**寄存器上下文和栈**，切换的时候会有保存和恢复，一般栈就2KB，可以动态伸缩，线程栈大概要2MB）
  - 操作系统中能同时运行多个进程；线程只是一个进程中的不同执行路径
- [ ] 进程有哪几种状态
  - 创建、就绪（等cpu就能运行，如果用完时间片也会进入就绪状态）、执行、阻塞、终止
- [ ] 进程调度策略
  - 先来先服务，直到完成
  - 短作业优先：系统预估每个进程需要的CPU时间，分配给预计需要时间最短的进程
  - 时间片轮转：每个进程分配一段固定的CPU时间
  - 多级反馈队列：将进程分配到多个队列中，每个队列有不同的优先级和时间片长度
- [ ] 文件描述符
  - 表述指向文件的引用，是一个索引值，指向内核为每个进程维护的打开文件的记录表。每打开或创建一个新文件返回一个文件描述符
  - "too many open files"解决
    - 句柄超出系统限制，通过ulimit -a可以查看当前系统设置的最大句柄数，lsof -p查看单个进程打开文件数，修改系统配置文件limits.conf可以增加
- [ ] 互斥锁的实现
  - 需要有一个标记锁状态的变量；需要记录哪个线程持有锁，需要有一个队列维护所有的线程
- [ ] 自旋锁的原理和实现
  - 当一个线程获取锁的时候，如果已经被其他线程获取，该线程将循环等待，然后不断地判断是否能够被成功获取直到成功。
  - 互斥锁如果资源被占用，会进入睡眠状态。
  - go实现：可以用一个状态位标志是否上锁，用atomic的cas方法去修改状态位。可以记录持有者以及记录加锁次数让其可重入。为了避免cpu过久空转，超过一定次数后进行上下文切换(可以用runtim.Gosched)，再之后自适应的添加sleep操作
- [ ] 判断链表是否有环
  - 哈希表缓存；快慢指针，快指针一次两步，慢指针一次一步，相遇时多走一倍的路程。
- [ ] map有几种实现
  - hashmap，速度最快，常数级，要保持一个array，有空间浪费
  - 红黑树，lg(n)，只保存节点，占用空间小，有序，遍历会好些。
- [ ] 开放定址法和链地址法的优缺点
  - 开放定址法：容易堆积，不适合大规模数据存储；散列函数设计对冲突影响大；可能会多次冲突；删除时需要对后面的冲突元素做处理，实现复杂；节点规模大时浪费空间
  - 链地址法：处理冲突简单，无堆积，平均查找长度短；节省空间，删除方便；缺点是指针需要额外空间，节点规模小时表现下降。
- [ ] 一致性哈希
  - 先求出节点的哈希值，分配到一个0-2^32的圆上
  - 用同样的方式求出key的哈希值，映射到相同的圆上
  - 从key映射的位置开始查找，选择遇到的第一个节点
  - 节点太少时容易数据倾斜，可以为一个节点映射多个虚拟节点，解决数据倾斜问题。一般虚拟节点数设置为32甚至更大
- 微服务
  - [ ] 微服务框架有哪些
    - spring boot
    - spring cloud
    - dubbo 通过rpc请求访问
    - istio google开发
    - go-zero
- RPC
  - [ ] rpc的整个调用过程
    1. 服务消费方以本地方式调用服务
    2. 客户端收到调用后将方法、参数组装成能够网络传输的消息体，然后找到服务地址，将消息发送到服务端
    3. 服务端收到消息后进行解码并根据结果调用本地服务，将执行结果结果打包成消息发送至客户端
    4. 客户端收到消息后进行解码然后发给服务消费方
  - [ ] 有http请求为什么还要用RPC
    - 可以采用自定义tcp协议，降低报头的占用；更多的是封装了服务发现、负载均衡、熔断降级一类面向服务的高级特性。
  - [ ] 不同RPC框架的优缺点
    - springcloud只支持java。grpc和thrift跨语言，两者相比起来gprc支持特性较少，代码简洁，文档详细
  - grpc vs restful
    - 使用proto文件编写api，restful用json
    - protobuf性能好
    - 用http/2，restful用http
    - 安全性高，可读性不如restful
    - 一般grpc是内部使用，restful对外
- [ ] 服务发现一般可以怎么做
  - 一种是服务消费方主动向注册中心新发起查询服务的请求；一种是服务订阅/通知变更：服务消费方向注册中心订阅某个服务，当服务信息变更时，注册中心主动通知消费者（注册中心提供服务注册、服务发现、健康检查的能力）。
  - etcd的实现：网关通过etcd获取到服务目录下的所有节点的信息，将他们初始化到自身维护的可访问服务节点列表中。然后使用Watch机制监听etcd上服务对应的目录的更新，根据通道发送过来的PUT和DELETE事件来增加和删除服务的可用节点列表。
- [ ] 负载均衡的算法
  - 轮询、随机、加权、最小连接数、hash
- [ ] 分布式事务的常见方案
  - 2PC
    - 两阶段提交是一种强一致性设计，引入一个事务协调者来协调管理参与者的提交和回滚。准备阶段给各参与者发送准备命令，同步等待所有参与者的响应；第二阶段也就是提交阶段，如果所有参与者返回成功则向所有参与者发送提交命令，所有参与者提交成功后返回事务执行成功。如果第一阶段有参与者返回失败，那第二阶段发送的就是回滚请求。如果第二阶段失败，不断重试。
    - 协调者容易发生单点故障。每个参与者的情况只有自己和协调者知道，如果协调者和某个参与者挂了，新的协调者不知道参与者的情况，即使记录了日志，也不知道有没有提交成功。
    - 同步阻塞容易导致资源长期锁定，降低效率
  - 3PC
    - 相比于2PC引入了超时，增加了一个预提交阶段
    - 准备阶段不会直接执行事务，而是询问参与者是否有条件，避免某些资源不可用时集体阻塞。预提交阶段类似2pc的准备阶段，并且有统一状态的作用。如果等待预提交命令超时，此时其实啥也没干，如果等待提交命令超时，直接提交(可能引入不一致问题)
  - tcc(Try-Confirm-Cancel)
    - 业务层面的分布式事务，Try代表资源的预留和锁定，Confirm代表确认，也就是真正的执行，Cancel是对预留阶段的撤销。
    - 思想上跟2pc差不多，先试探是否能执行，如果可以就真的执行
    - 每一个操作都要定义tcc三个动作，对业务侵入较大；撤销和确认可能要重试，需要做幂等。
    - try消息丢包可能会超时，此时会触发二阶段回滚，调用cancel。未收到Try的情况下收到cancel就是空回滚。空回滚之后又收到了之前的try，这时要拒绝执行，如果执行的话就会悬挂，因为无法收到之后的confirm或者cancel。
    - 一般认为cancel和confirm不会失败，如果真的出错了，重试或者人工处理。
  - 本地消息表
    - 有一张存放本地消息的表，业务的执行和将消息放入消息表两个动作放在一个事务中，消息状态是“发送中”。消息会经过mq发送到消费者，消费成功后修改消息表中的状态为已发送。有一个定时任务去重试“发送中”的消息，也要做幂等。实现最终一致性，容忍暂时不一致。
  - 消息事务
    - 先给broker发送半消息，然后执行本地事务，根据执行结果向broker发送提交或者回滚命令。发送方提供一个反查接口，如果一段时间半消息没有收到任何请求，会反查是否执行成功。如果成功，订阅方执行本地事务然后再消费消息。
  - 最大努力通知
    - 一种思想，其实本地消息表和消息事务都算最大努力。消息表中失败的任务/commit的消息会多次重试
- [ ] 雪花算法
  - 可以用来生成分布式唯一id。总共64位，1位符号位，41位时间戳，10位机器标识，12位计数序列号。
  - 时间回拨的话可以阻塞等待或者报错，也可以利用扩展位，回拨之后在扩展位加1
- [ ] 倒排索引：普通索引根据文档找关键词，倒排索引根据关键词找文档
- [ ] 设计模式
  - 创建型模式
    - 工厂模式：父类中提供一个创建对象的方法，允许子类决定实例化对象的类型
    - 抽象工厂：为每件产品明确声明接口(比如椅子、沙发)，所有的产品变体都继承这些接口(所有风格的椅子都实现椅子接口)，接着声明抽象工厂，包含所有产品构造方法，这些方法返回的都是抽象产品类型。每个变体基于抽象工厂接口创建不同的工厂类(现代风工厂、复古风工厂)。
    - 生成器模式：允许将对象构造过程划分为一组步骤(比如盖房子划分成创建墙壁、门等)，每次创建时执行一系列步骤，允许只用一部分。
    - 原型模式：将克隆过程委派给被克隆对象，模式为所有支持克隆的对象声明一个通用接口，能克隆对象同时不用和对象所属类耦合
    - 单例模式：保证一个类只有一个实例，并提供一个访问该实例的全局节点。最常见的原因是为了控制某些共享资源。
  - 结构型模式
    - 适配器模式：使接口不相容的对象能够相互合作。适配器实现一个与现有对象兼容的接口，适配器方法被调用后将以另一个对象兼容的格式和顺序传递给给对象，甚至可以用双向适配器。
    - 桥接模式：将一个大类拆分为抽象和实现两个独立的层次结构。比如形状和颜色，比如GUI和API
    - 组合模式：可以使用它将对象组合成树状结构。比如一个盒子中可以装若干个盒子，也可以装订单。
    - 装饰模式：需要更改对象的行为是，第一反应可能是继承，但是继承无法更改已有对象的行为，大多数也不允许同时继承多个类的行为。可以使用组合来代替，一个对象包含指向另一个对象的引用，并将部分工作委派给引用对象。比如人可以使用不同的工具获得不同的功能。
    - 外观模式：为包含许多活动部件的复杂接口提供一个简单的接口，但却包含了用户真正关心的功能。比如电话购物，接线员就是所有服务和部门的外观
    - 享元模式：对象的常量数据称为内在状态，其他对象读取但不修改，其他状态能被其他对象从外部改变，称为外在状态。享元模式不建议在对象内存储外在状态，以方便在不同情境下重用
    - 代理模式：代理模式建议新建一个与原服务对象接口相同的代理类，代理类收到请求后会创建实际的服务对象，并将所有工作委派给他。如果需要在主要逻辑前后执行一些工作，无需修改类就能完成。比如信用卡和现金。
  - 行为模式
    - 责任链模式：允许将请求沿着处理者链条发送，收到请求后每个处理者均可对请求进行处理或将其传递给下个处理者。
    - 命令模式：将请求转换为一个包含与请求相关的所有信息的独立对象。比如在餐厅记录点菜信息的那张纸。
    - 迭代器模式：在不暴露底层表现形式的情况下遍历所有元素。迭代器通常会提供一个获取集合元素的基本方法。 客户端可不断调用该方法直至它不返回任何内容， 这意味着迭代器已经遍历了所有元素。除实现自身算法外， 迭代器还封装了遍历操作的所有细节。
    - 中介者模式：该模式建议你停止组件之间的直接交流并使其相互独立。 这些组件必须调用特殊的中介者对象， 通过中介者对象重定向调用行为， 以间接的方式进行合作。 最终， 组件仅依赖于一个中介者类， 无需与多个其他组件相耦合。
    - 备忘录模式：允许在不暴露对象实现细节的情况下保存和恢复对象之前的状态。备忘录模式将创建状态快照的工作委派给实际状态的拥有者原发器对象。模式建议将对象状态的副本存储在一个名为备忘录的特殊对象中。 除了创建备忘录的对象外，任何对象都不能访问备忘录的内容。
    - 观察者模式：允许你定义一种订阅机制，可在对象事件发生时通知多个 “观察” 该对象的其他对象。
    - 状态模式是：让你能在一个对象的内部状态变化时改变其行为， 使其看上去就像改变了自身所属的类一样。原始对象被称为上下文，它并不会自行实现所有行为，而是会保存一个指向表示当前状态的状态对象的引用，且将所有与状态相关的工作委派给该对象。如需将上下文转换为另外一种状态，则需将当前活动的状态对象替换为另外一个代表新状态的对象。比如手机解锁时按下按键可以执行功能，锁定时按下任何按键都是解锁屏幕。
    - 策略模式：定义一系列算法，并将每种算法分别放入独立的类中，以使算法的对象能够相互替换。名为上下文的原始类必须包含一个成员变量来存储对于每种策略的引用。上下文并不执行任务，而是将工作委派给已连接的策略对象。和状态模式的区别是，状态模式对其他状态是已知的，策略模式对其他策略是未知的。比如可以做飞机、高铁、汽车出行。
    - 模板方法模式：它在超类中定义了一个算法的框架，允许子类在不修改结构的情况下重写算法的特定步骤。抽象步骤必须由各个子类来实现，可选步骤已有一些默认实现， 但仍可在需要时进行重写，钩子是内容为空的可选步骤，通常放置在算法重要步骤的前后，为子类提供额外的算法扩展点。
    - 访问者模式：新行为放入一个名为访问者的独立类中，而不是试图将其整合到已有类中。原来的对象需要接受一个访问者并告诉其应执行的访问者方法。比如保险员拜访每栋楼，可以根据不同的类型提供不同的保单。
- [ ] 虚拟内存、虚拟地址空间
  - 虚拟内存时计算机系统内存管理的一种技术，使应用程序认为他们拥有连续的可用内存，实际上这些内存是分散在物理内存和硬盘上的。简化内存管理，提高内存利用率，保护应用程序间的隔离。
  - 虚拟地址空间：操作系统给每个进程提供一个独立的虚拟地址空间
  - 页表：一种数据结构，存虚拟地址到物理地址的映射关系，存在物理内存中，由操作系统维护。操作系统会将页表的部分或全部内容映射到虚拟地址空间，方便访问和管理页表。
- [ ] 缺页中断
  - 当程序访问的虚拟地址对应的物理内存页不在内存中时，触发缺页中断，操作系统需要将所需的物理页从硬盘加载到内存中，并更新页表。中断次数=进程中的物理块数*页面置换次数
- [ ] 进程间通信方式有哪些
  - 管道：分为命名管道和无名管道，在内核中申请一块固定大小的缓冲区，拥有固定的读端和写端。无名管道一般是基于父子进程的通信，命名管道用于没有血缘关系的进程通信。
  - 消息队列
  - 共享内存：将同一块物理内存映射到不同进程的虚拟地址空间，实现不同进程对统一资源的共享。最快的进程通信方式，不需要用户态到内核态的频繁切换和拷贝数据。操作临界资源需要保证完整性。
    1. 创建共享内存区，通过shmget
    2. 把这块共享内存映射到两个进程的地址空间上，通过shmat
    3. 完成通信后，通过shmdt进行脱离，撤销映射关系
    4. 删除共享内存，通过shmctl实现
  - 信号量
  - socket：服务端和客户端各自维护一个“文件”，建立连接后可以读文件或者向自己文件写入内容供对方读取，通讯结束后关闭文件。
- [ ] 原子操作底层原理
  - 基于缓存加锁和总线加锁。
  - 总线锁是处理器提供的一个lock信号，可以阻塞其他处理器的请求，开销较大。
  - 频繁使用的内存会缓存在处理器的高速缓存里，原子操作可以直接在处理器内部缓存中进行。如果内存被缓存在处理器的缓存行中，并且lock期间被锁定，当回写内存时不会再总线上加锁，而是修改内部的内存地址，借助缓存一致性机制保证操作的原子性。
  - 如果操作的数据不能缓存在处理器内部或者操作数据跨多个缓存行，会调用总线锁。
- [ ] 为什么操作系统所有进程都要设计父进程？
  - (没找到好的解释)方便管理、安全稳定
- [ ] 线程池
  - 核心参数：核心线程数量、最大线程数、多余的空闲线程存活时间、工作队列、线程工厂、拒绝策略
  - 还要保存当前线程数，线程池状态，提供池的创建关闭、任务提交、线程增减等方法。
  - 协程池类似。

## go

- 通道
  - 本质上讲通道就是一个基于锁的循环队列，首先获取锁，然后进行竞争检查、指针检查，然后更新读写位置，记录数据，释放锁
  - [ ] **收发通道**
    - 收发通过<-进行，如果没有缓冲且无接受，发送方阻塞
    - 接收是阻塞的，如果想非阻塞应该用“，ok”，会造成较高的CPU占用，一般只配合select做超时检测
  - [ ] 什么时候报panic/死锁
    - 关闭未初始化/已关闭的通道会panic
    - 发送给未初始化的通道会死锁，给关闭的通道会panic
    - 接收未初始化的通道会死锁
  - [ ] **通道有什么用**
    - 解决go协程的同步和数据共享问题
  - [ ] 单向通道
    - 可以用来约束其他代码的行为，chan<- int, <-chan int
    - 调用`func SendInt(ch chan<- int)`时可以传一个双向通道进去，go会自动转换成函数所需的单向通道
  - [ ] chan内存泄漏
    - 接收者已经退出/因为异常提前退出，发送者阻塞
- slice
  - [ ] 切片和数组的区别
    - 切片是可变长度，数组是固定长度，数组的长度是属性的一部分。
    - 切片相当于是对数组的一个封装，包括一个指针指向底层数组以及len和cap。
  - [ ] 切片扩容
    - 如果new cap>2*old cap，直接扩容到new cap
    - 如果old cap小于1024，扩容翻倍
    - 如果大于1024，每次扩容25%，避免浪费
  - [ ] 并发的问题
    - append并发执行不会报错，但是会丢数据，比如append
  - string和[]byte可以通过指针强转，实现不分配额外内存的转换
  
    ```golang
      func String2Bytes(s string) []byte {
          sh := (*reflect.StringHeader)(unsafe.Pointer(&s))
          bh := reflect.SliceHeader{
              Data: sh.Data,
              Len:  sh.Len,
              Cap:  sh.Len,
          }
          return *(*[]byte)(unsafe.Pointer(&bh))
      }

      func Bytes2String(b []byte) string {
          return *(*string)(unsafe.Pointer(&b))
      }
      ```

  - append似乎一定会返回一个新的切片(TODO：不确定)
- map
  - [ ] **map的实现**
    - map是对hmap的指针，每个map的hash会基于一个随机的种子，插入时先生成一个hash value，根据后面的字节确定bucket，根据前面的字节确定在bucket内部列表的顺序(golang相当于是链地址法)；bucket内先保存所有的key，再保存所有的value，可以减少填充使用的内存空间；bucket满之后会创建一个overflow的bucket跟在后面，过多的overflow会降低性能。装载因子(元素的填满程度，越大越容易哈希冲突)超过负载后map就会成倍扩容，扩容后的迁移不是一次性的，使用时如果发现在旧的buckets才会搬迁；map不能并发的写，通过flags来实现。如果溢出桶过多，会触发等量扩容回收冗余溢出桶。
  - [ ] go里面map为什么是无序的
    - for range遍历map索引的起点是随机的。这样做的原因可能是，go中的map本质上就是无序的，写的时候并没有维护键值对的顺序。
  - [ ] map并发操作有什么问题
    - map中有一个flag记录状态，如果有并发读写会报panic。可以通过读写锁避免，数据量大的时候会影响性能。
  - [ ] 哪些类型可以当key
    - 可比较的类型都可以作为map的key，不能的类型包括切片、map、函数
- [ ] defer机制
  - 是一种延迟调用机制，defer后面的函数只有在当前函数执行完毕后才能执行，语句会按defer的逆序执行
  - defer延迟函数的参数在defer声明时就确定了，如果defer的函数参数包含子函数，会先计算子函数。
  - defer和return的关系：在返回值赋值之后，在RET指令之前
  - defer和panic的关系：会先执行所有的defer，如果都执行完且没有recover，才会进行panic
- [ ] GMP模型
  - G即goroutine，存执行时的堆栈信息，状态以及任务函数等；P表示processer，P的数量决定了系统内最大可并行G的数量,M可以理解成内核线程。线程想运行任务要从P的本地队列获取G，如果本地队列为空，要从全局队列获取或者从其他P的本地队列偷取。如果一个M阻塞，P会去切换后者创建另一个M
  - 为什么拆分本地队列和全局队列：老版本的go是GM模型，调度需要锁，形成了激烈的竞争；老版本局部性比较差(如果M创建了G'，为了继续执行G需要把G'放在全局队列，但是G'最好在之前的M上执行)
- sync
  - [ ] 互斥量sync.Mutex
    - 可以用来保护一个或一组相关临界区，保证同一时刻只有一个goroutine处于临界区内，进入临界区要加锁，离开及时解锁
    - 不要重复加锁，不要忘记解锁，不要重复解锁（解锁未锁定的锁会panic），不要复制锁
    - 锁可以认为是信号量为1的情况
  - [ ] 读写锁sync.RWMutex
    - 多个写操作不能同时进行，写操作和读操作也不能同时进行，多个读操作可以同时进行。
    - 对写锁解锁，会唤醒所有因试图读被锁定的goroutine
    - 对读锁解锁，如果没有其他读锁，会唤醒等待写锁的goroutine，只有等待时间最长的goroutine能完成写锁锁定
    - 解锁未锁定的读写锁会panic
  - [ ] 条件变量sync.Cond
    - 用于协调访问共享资源的线程，共享资源状态发生改变时，可以用来通知被互斥锁阻塞的线程。
    - signal和broadcast不涉及锁，wait被调用时一定要加锁，先将调用者加入阻塞队列，释放锁然后进入阻塞等待状态。

      ```golang
      func (c *Cond) Wait() {
        c.checker.check()
        // 增加到等待队列中
        t := runtime_notifyListAdd(&c.notify)
        c.L.Unlock()
        // 阻塞休眠直到被唤醒
        runtime_notifyListWait(&c.notify, t)
        c.L.Lock()
      }
      ```

    - 大部分都可以用channel实现，这个更底层一点。可以重复调用，同时支持signal和broadcast，channel只能支持其中的一种。
  - [ ] sync.pool
    - 提供对象重用机制，是一个并发安全的、可伸缩的临时对象池，用来存放已分配暂时不用的对象。其中存放的值可以在任何时候被删除而不收到通知，可以动态扩容或收缩，gc的时候会清除掉所有的值。
    - 为每个P分配一个本地池，执行时将goroutine和某个P做关联，访问私有对象不用加锁，访问共享列表对象要加锁。put空直接返回，否则检查当前goroutine的private是否设置，如果没有则设置为x，已设置则把x追加到共享列表。get时首先从p对应的池获取，获取失败从共享列表获取，仍然失败会从其他P的对象池偷一个过来，只要获取成功就从中删除。如果最后也失败就new一个，直接返回。
    - 本地池列表中本地池的数量和 golang 调度器中 processor 的数量相等，也就是说每个本地池对应一个 P
  - [ ] sync.map
    - 空间换时间，通过冗余的两个数据结构(read、dirty)减小加锁的影响
    - 使用只读数据，避免读写冲突
    - 动态调整，miss次数多了后会将dirty数据提升为read
    - double-checking
    - 延迟删除
    - 优先从read读取、更新、删除
    - 读取时首先从read中读，不需要加锁；如果read没有，并且dirty中有新数据，加锁后从dirty找，(加锁后再查一次read防止期间dirty被提升为read)，不管dirty中有没有key都会将miss计数加一。对于更新/增加少，加载存在的key很多的情况下性能很好。
    - store时先看read中是否存在key，如果存在且没有被标记删除尝试直接存；否则加锁后更新dirty
    - 删除时如果read中存在，打标记。如果不存在且dirty中有新数据，加锁从dirty删。
    - range前如果dirty中有新数据，会做一个dirty的提升
- goroutine协作
  - runtim.Gosched()主动切换上下文，因为系统调用、互斥锁或通道而被阻塞时也允许切换上下文。
  - context
    - [ ] waitgroup的劣势
      - 一个线程等待其他线程完成，只能实现一对多的线程等待，不支持嵌套层次
      - 需要注意并发数和线程等待数的一致，不一致的话会panic
    - 用于管理协程的生命周期，是协程并发安全的
    - 可以根据已有的context派生新的，只要取消一个派生出来的都会关闭，形成一个多叉树,这棵树的树根（或者称上下文根节点）是一个已经在context包中预定义好的Context值，它是全局唯一的。通过调用context.Background函数可以获取到它
    - Context类型，Done返回一个信号结束的channel，Deadline返回一个任务停止执行的截止日期，Value返回一个多线程安全使用的Value
    - 四个用于繁衍Context的函数：WithCancel、WithDeadline、WithTimeout和WithValue，函数的第一个参数都是parent
      - 除了WithValue都会返回一个Ctx和一个用于手动撤销的函数，WithDeadline和WithTimeout还会根据定时自动撤销
      - WithValue得到的Ctx是不可撤销的，撤销信号传播时会跳过然后试图直接传给它的子值，Value不可更改，查找的时候会从自己开始往根节点方向查找。
  - [ ] go协程数量控制
    - 固定个数，比如semaphore信号量（规定上限，获取、执行、返还）；漏桶：处理速度是固定的，如果桶满了会丢弃请求，不太适应突发流量；令牌桶：以指定速度生成令牌，达到上限后丢弃令牌，请求需要拿到令牌才能执行，对漏桶的改进；协程池。
  - [ ] 并发安全的计数器
    - 使用sync的互斥锁（读写锁可以兼顾读）
    - 使用channel，在另一个线程里顺序执行channel里的操作
    - 使用atomic执行原子的add或者cas(不适于浮点数)
- I/O多路复用
  - 单一线程同时监听多个文件描述符(I/O事件)，阻塞等待，并在某个文件描述符可读写时收到通知。
  - [ ] select
    - 包括默认分支和候选分支，候选分支的表达式中必须包含通道发送或者通道接收
    - 候选分支中的case表达式都会在该语句执行开始时先被求值，并且求值的顺序是依从代码编写的顺序从上到下的
    - 仅当所有 case 表达式都被求值完毕后，select 语句才会开始选择候选分支
    - 如果求值时对应操作是阻塞的，求值不成功，不满足选择条件
    - 所有候选分支阻塞时才执行默认分支，这与默认分支的位置无关。如果没有默认分支，会阻塞直到某个候选分支满足条件，
    - 如果有多个完成的，会随机选一个
  - [ ]epoll
    - select最大的问题在于单进程打开的文件描述符有限制，并且每次调用都要把fd集合拷贝到内核态，每次都要线性扫描整个fd集合，fd多时性能下降。
    - 先用epoll_create创建一个epoll对象实例epfd，内部存储监听列表（红黑树）和就绪列表（链表）。通过epoll_ctl将要监视的fd添加到epfd，同时为fd设置一个回调函数，当事件发生时会调用回调函数，并把fd添加到就绪队列。最后调用epoll_wait阻塞监听epoll上所有的fd的I/O事件，如果就绪列表中有数据直接返回。
      - 优点：红黑树插入删除性能稳定，并且可以存大量的fd。不需要像select遍历每个文件描述符，直接看就绪列表是否为空。
- [ ] tag
  - 字段上额外增加一个属性，用反引号包括。可以用来指定序列化反序列化时的字段名，可以忽略某个字段，忽略空值字段，处理输出。
- [ ] 读文件
  - 通过判断EOF标记可以判断文件是否读完，ReadAt可以指定读文件的偏移量。
- [ ] go 故障排查
  - 先止血：重启/限流/回滚；服务监控：查看CPU/内存/负载等(负载是指可运行状态和不可中断状态的进程数)；故障复盘：处理记录、原因分析、整改
- [ ] go 性能分析
  - 引入pprof，可以import "net/http/pprof"，然后访问localhost:port/debug/pprof生成报告，用`go tool pprof -http="0.0.0.0:8080" {{name}}.out`分析，常用命令top +num看最高的n个，list+函数名看执行，traces看调用，png或者svg可视化
  - benchmark性能测试：测试cpu和内存的效率来评估性能，代码文件必须以_test.go结尾，测试函数必须以Benchmark开头，必须是可导出的，不能有返回值，必须接受一个指向Benchmark类型的指针作为唯一函数。可以指定cpuprofile或者memprofile结合pprof查看

    ```go
      func BenchmarkSprintf(b *testing.B){
        num:=10
        b.ResetTimer() //b.ResetTimer是重置计时器
        for i:=0;i<b.N;i++{ //框架提供的循环次数
          fmt.Sprintf("%d",num)
        }
      }
    ```

- [ ] go 远程调试
  在远程服务器安装dlv，启动dlv，在ide配置debug监听端口
- [ ] go 内存管理
  - 栈的内存管理与线程相关，函数调用时把函数和变量压入栈，一旦线程执行结束则释放相应内存空间
  - 堆，类似tcmalloc的多级内存分配，小对象走mcache，span(内存块)都被占用向mcentral申请，没有符合条件的则向mheap申请，mheap没有则向os申请
  - gc最早使用标记清除，stw时间长；1.5使用三色标记，借助插入屏障（堆上被插入的节点标记为灰色，为了效率只在堆上开启，结束时stw重新扫描栈）和删除屏障（被删除的节点也标记为灰色，该节点可以活到下一轮gc，精度低）；1.8混合写屏障，栈不启动写屏障，一开始把栈上的对象全部扫描并标记为黑色，gc期间栈上创建的新对象也均为黑色，被删除和添加的堆对象标记为灰色。标记结束后不需要重新扫描栈，减少stw时间
  - gc触发：内存分配达到阈值；定期触发；手动触发；
- [ ] 内存泄漏
  - 未及时关闭资源，比如文件、网络连接等使用完成后没有关闭
    - 及时关闭资源，可以使用defer关键字
  - 协程泄露，没有正确的关闭或释放协程，导致协程持续运行。
    - 使用context包管理协程的生命周期
  - 使用性能分析工具
  - 使用代码检测工具并进行代码审查
- [ ] 内存逃逸
  - 函数返回局部变量指针
  - 发送指针或带有指针的值到channel，编译器无法确定变量的释放时间
  - interface类型逃逸
    - `fmt.Printf("%v", str)` 值逃逸
    - `fmt.Printf("%p", &str)` 只有值传递，地址被装在一个堆上的变量里，堆上的变量不能存栈上的地址，str逃逸到堆上，在堆上分配内存
  - 闭包产生逃逸
  - 栈空间不足
  - 使用指针类型的切片
- [ ] go伪继承
  - 用匿名嵌套实现
  - 组合优于继承：继承层次过深、继承关系过于复杂时会影响代码的可读性和可维护性。
  - 比如很多鸟会飞，但是也有不会飞的，如果分成会飞不会飞的两类，下不下蛋要不要分？
- [ ] go单例模式
  - 饿汉式，加载时创建唯一实例，然后每次都返回这个实例
  - 懒汉式，第一次使用时创建，用sync.once确保只执行一次
- [ ] CSP
  - 两个独立的并发实体通过共享的通讯管道进行通信
  - 通过协程和通道实现，通过通信来共享内存
- [ ] go和C++的区别
  - C++是一种面向对象的编程语言，Go是程序性的编程语言
  - C++支持继承和重载，Go不支持
  - C++支持带构造函数的类，Go不支持

## redis

- [ ] **简介**
  - 服务器循环处理事件，包括文件事件（建立连接，读写，关闭连接）和时间事件（一般只有serverCron，执行清理过期键、AOF重写、RDB的savepoint检查等）
  - 文件事件是对socket操作的一个抽象，I/O多路复用程序同时监听多个socket，产生文件事件时触发事件通知，将所有事件的socket放入一个队列，文件分派器感知并获取这些事件。
  - 适合较小数据量的高性能计算
- [ ] **redis为什么快**
  - 内存存储
  - 单线程实现（所有网络请求用一个线程处理,省去切换上下文的时间）+非阻塞多路复用I/O(减少网络上I/O的时间)
  - 优化的数据结构
  - redis自己构建了虚拟内存机制，把暂时不经常访问的数据从内存交换到磁盘
  - 内存+单线程免切换+多路复用也可以用来答高并发
- [ ] **redis数据类型**
  - string（缓存结构体消息，计数，len+free+buff，最后一个是空字符。追加的时候先看够不够存，如果不够开辟到满足要求，然后申请与len相同的空闲free，如果大于1M就只申请1M）
  - list（可以实现异步队列，可以实现点赞功能，lrem可以移除指定的value）
  - hash（保存结构体，可以单独保存某个字段）
  - set
  - zset（借助跳表实现，相比红黑树实现简单，插入删除快，范围查询方便，内存占用小）
  - 位图（以位为单位的数组，适合统计数据，比如20亿个qq号o(1)查找）、Hyperloglog、Geospatial（存地理信息）
- [ ] redis hash表
  - 用链地址法解决冲突
  - 扩展收缩
    - 假设使用大小为x，扩展的话扩展为第一个大于2*x的2的次方，收缩的话为第一个大于x的2的次方
    - 负载因子大于1扩展，小于0.1收缩，如果正bgsave或者bgrewriteaof，扩展阈值是5，为了避免此时扩展导致不必要的内存写入。
    - 分多次渐进rehash，防止服务停止
- [ ] ziplist/quicklist
  - ziplist是Redis list、hash、zset的底层实现结构之一，当list、hash、zset中节点数量较少，并且存储的大多节点为小整数型，较短的字符串时，Redis就会使用ziplist作为list、hash、zset的底层实现。
  - ziplist不存储指向上一个节点和下一个节点的指针，而是存上一个节点和当前节点的长度。存上一个节点长度是因为压缩列表数据不规则紧邻，无法通过后退指针找到上一个元素，通过当前地址减去上一个节点的长度可以找到上一个节点的位置向前回溯。
  - 链表的附加空间太高，且会加剧碎片化，对list进行了改造，用quicklist取代了ziplist和linkedlist。将linkedlist按段切分，每段使用ziplist来紧凑存储，多个ziplist之间用双向指针串起来。插入可能会涉及到节点的创建或者分裂。
- [ ] redis提高数据库容量的方式
  - 将数据分割到多个redisServer上
  - 使用虚拟内存把不经常访问的数据交换到磁盘上
- [ ] redis怎么去重
  - 可以用set的集合特性，如果数字型的数据可以用bitmap，存储空间更小。
- [ ] **redis持久化**
  - 分为RDB和AOF以及混合三种。RDB是默认存储方式，保存某一时刻数据的快照，符合自定规则/执行save、bgsave（阻塞时间短）、flushall命令/第一次主从复制会触发快照，优点是占用空间小，性能好，缺点是会丢失最后一次快照以后的数据；AOF记录写过的所有命令，按顺序回放进行恢复，如果AOF体积过大，会自动重写成恢复当前数据集的最小的命令集合，缺点主要是性能差，不建议单独使用。
- [ ] 持久化数据和缓存扩容
  - 当做缓存使用，使用一致性哈希实现动态扩容缩容
  - 当作持久化存储使用，必须使用固定的keys-to-nodes映射关系，节点数量一旦确定不能变化，否则必须使用可以运行时数据平衡的一套系统（比如redis集群）
- [ ] **redis过期键的删除策略**
  - 惰性删除+定时删除：惰性删除指的是不会主动删除数据，在访问时再检查是否过期，(cpu友好、空间浪费)；定时删除是指redis会周期性的随机测试一批设置了过期时间的key并处理，测试到的已过期key会被删除(空间友好、影响cpu)
- [ ] redis过期相关命令
  - expire(按秒设置过期)、pexpire(按毫秒过期)、persist(移除过期时间)、ttl(查看剩余时间)
- [ ] **内存淘汰策略**
  - 内存不够用时触发淘汰策略，删除一些不常用的数据
  - 移除设置过期时间的key(最近最少使用/最不经常使用/将过期的/随机)、移除数据集中的(最近最少使用/随机/最不经常使用的key)、禁止写入数据
- **缓存(使用redis做缓存)**
  - 缓存异常有四种类型：缓存与数据库不一致、缓存击穿、缓存雪崩、缓存穿透
    - [ ] 缓存与数据库不一致
      - 有四种方案保证缓存与数据库双写时的数据一致性：先更新数据库后更新缓存(导致缓存中脏数据)、先更新缓存后更新数据库(如果数据库失败会造成不一致)、先删除缓存后更新数据库(为了防止删除期间有人读，可以延时双删)、先更新数据库后删除缓存(删除可能失败，可以用消息队列进行补偿删除)
    - [ ] 缓存击穿
      - 某个热点key失效，大并发集中进行请求导致高并发访问数据库。可以通过互斥锁或者队列来控制读写缓存的线程数量，其他线程阻塞，吞吐量下降；也可以对热点key不设置过期时间，或者要过期时通过后台异步线程进行缓存的构建
    - [ ] 缓存雪崩
      - 大规模的key失效导致大量请求打在数据库上，有两种可能：一种是redis宕机；一种是采用了相同的过期时间。
        - 事先：均匀过期、热点key不过期或者过期前刷新、分级缓存并且每级失效时间不同；保证redis高可用；
        - 事中：互斥锁限制读写缓存的数量(吞吐量下降)；使用熔断机制限流降级，部分用户可用，其他用户刷新几次后得到结果
    - [ ] 缓存穿透
      - 用户请求的数据在redis中不存在，大量的请求打在数据库上。如果空的key有限或者重复率高，可以将无效的key也写入redis；否则可以使用布隆过滤器提前判断key，判断不存在则一定不存在、直接返回，判断存在则大概率存在(可能误判)
      - 布隆过滤器是一个超大的位数组和几个哈希函数，假设有k个哈希函数，对每个元素通过k个哈希函数进行映射，数组对应的k个位置记为1。查询的时候做同样的映射，如果这k个点都为1，则可能存在(有可能误判，比如是多个不同元素哈希得到的1)，否则一定不存在。
  - [ ] 缓存预热：系统上线后先把数据加载到缓存系统，防止初始状态时高并发的访问数据库
  - [ ] 缓存降级：缓存失效时不去访问数据库而是直接返回默认数据或者内存结果，一般是有损的操作，要尽量减少对业务的影响
- [ ] redis事务
  - 不是传统意义上的事务，只是一个批量执行脚本，一条命令失败不会导致之前的命令回滚，之后的命令也依然会执行，不满足原子性。
  - 执行时故障，如果没开启rdb或aof，重启后无数据，一致；如果开了rdb，事务操作不记入，恢复后也一致；如果用了aof，没记录时故障之后恢复一致，记录一部分后可以用redis-check-aof清除事务中已完成的操作，恢复后一致
  - 单线程可以保证并发不破坏隔离性，用watch监视值的变化，如果值已经修改就放弃事务，可以保证隔离性。。
  - rdb可能会丢最后一次快照之后的操作，aof也都存在数据丢失的情况。不保证持久性。
- [ ] **常见使用方式**
  - 单副本：简单方便性价比高；不保证可靠性
  - 主从：实时同步，高可靠，读写分离；故障恢复复杂，需要手动升主并让其他从复制，写能力和存储能力受限
  - 哨兵：自动实现故障发现、故障自动转移、配置中心和客户端通知；从节点不提供服务带来资源浪费、不能读写分离、只有针对主节点的高可用切换。不支持水平扩容，可以监控多个主。
  - 集群：解决单机内存、并发、流量等瓶颈，最少6节点，主提供读写，从备用。无中心、数据存储在多个节点、可扩展、高可用；实现复杂、容易因为阻塞下线、异步复制不保证强一致性、无法区分冷热数据、批量操作受限、事务受限
  - 自研
- [ ] redis主从复制
  - 如果是slave重连，只复制缺少的部分，否则进行完全同步：生成一份rdb文件同时将客户端收到的写命令缓存在内存，然后将rdb发送给从，从先写入磁盘再加载到内存，然后同步之前缓存的写命令的数据。如果复制过程中连接断了，支持断点续传
- [ ] cluster主掉了怎么恢复，从升主要做什么
  1. 故障发现：也经历主观下线和客观下线两个阶段，要求每个节点不停的ping其他的节点，长时间不同就标记主观下线，其他节点也跟着判定，半数以上认为则标记为客观下线，接着广播客观下线信息
  2. 当下线节点的slave收到消息后，开始故障迁移，检查自身是否具备竞选资格（长时间不和master通信就不具备），竞选部分类似raft，只有主节点有投票资格，获得一半以上主的投票就开始替换之前的master。如果自己没有slave条件允许的话可以问别人借slave
  3. 替换就是标记自己为主，然后将其负责的slots标记为自己负责，最后广播给集群，其他节点收到信息后更新维护的状态和slots的设置。
- [ ] 为什么推荐奇数个节点
  - 比如三个节点和四个节点，都是只允许宕机一台（要半数以上投票），所以从成本上不推荐偶数个节点
- [ ] redis哨兵工作
  - 哨兵每秒一次ping其他的主、从、哨兵
  - 如果一个实例最后一次有效回复超过了规定的时间，将其标记为主观下线
  - 如果一个master被标记为主观下线，所有哨兵以每秒一次的频率确认其的确进入主观下线，如果足够数量的哨兵都这样认为，标记为客观下线，此时会加快发送给其slave消息的频率
  - 若没有足够数量的哨兵同意，客观下线会变成主观下线，如果重新回复了ping，主观下线会移除
  - 客观下线后，哨兵投票选一个哨兵节点进行故障处理，在从节点中选一个主，其他节点挂载到新的主节点并自动复制主节点的数据。
  - [ ] 选为master的标准：跟master断开的时长 > slave优先级 > 复制的数据多少 > run id
- [ ] **redlock**
  - 属性建模：互斥、没有死锁、大多数节点工作就可以使用
  - 最简单的是创建一个带超时的key，释放时删除。但是如果主宕机时，主从复制是异步的，新的主可能没有key的信息。
  - 单个实例的正确实现：value设置为一个随机值，在所有客户端和请求中唯一（比如用客户端id加时间戳），释放时只有key存在且value是期望的值才删除(用lua脚本确保原子性)
  - redlock算法：单个实例中还是用之前的方法，获取当前时间后顺序的获取所有N个实例中的锁，在所有的实例中使用相同的密钥和随机值。获取锁的超时时间相比锁的超时时间要足够小，如果有一个实例不可用，尽快与下一个对话。客户端从当前时间减去一开始获取的时间计算获取锁的花费，比如能在大多数实例获取锁并且总时间小于有效时间，才认为锁被获取。如果获取成功，有效时间是初始有效时间减去经过的时间；如果获取失败，尝试解锁所有的实例。失败后在随即延迟后重试。
  - 算法需要本地时间流速相同，要在有效时间减去几毫秒补偿时钟飘逸。实例重启后不再参与当前活动的锁就基本是安全的。挂钟移位可能导致多个进程获取锁。需要大量时间的进程最好实现屏蔽令牌，不要假设只要进程活着锁就会保留。
- [ ] redis cluster如何实现数据分布
  - 有16384个hash slot，每个master持有部分slot，增加一个master就把其他master的slot移动部分过去，减少一个master就把它的slot移动到其他master，移动的成本非常低。
  - 集群会通过心跳发送包括slot bitmap消息，16384相比65536传送时占的空间小，对于预计1000个master的集群，每个节点的slot也不至于太少
<!-- - [ ] 分片hgetall有什么问题 -->
- [ ] 跳表
  - 对链表加多级索引就是跳表，近似二分查找
  - 插入的时候现在底层插入，然后不断“抛硬币”看是否能加入上一层；删除的时候删除所有的这个节点
  - 空间换时间
  - 对比红黑树：性能相当、实现简单、区间查询跳表效率更高；不如红黑树稳定、空间浪费
- [ ] redis内存优化
  - 控制key的数量，可以利用redis的数据结构
  - 缩减键值对象的长度
  - 编码优化
- [ ] 慢查询分析
  slowlog get：显示超过预先设置阈值的指令。每一条包括ID、命令执行的时间戳、执行时长、命令和参数
  可能的原因：
  - 频繁获取短链接或者最大连接数过小导致等待会增大连接开销
  - 网络请求开销可能会导致慢
  - 使用复杂度高的命令或者一次返回的数据量过多。
  - 存在bigkey：含有较大数据或者大量成员、列表。可能要拆分、清理、监控内存。
  - 缓存集中过期，定时删除key的时候时在主线程运行的，会增大时延
  - 内存达到上限，每次要先内存淘汰再写，也很耗时
  - 后台持久化需要fork，如果实例很大，fork也很耗时
- [ ] hotkey/bigkey
  - 可以通过hotkeys/bigkeys命令查询得到或者用monitor输出信息到文件然后去找
- [ ] redis是ap还是cp
  - 集群是AP系统，当部分节点下线后，可以提供正常节点的服务。
  - etcd、zookeeper是cp的
- [ ] redis 原子操作
  - INCR、DECR原子加减
  - Lua脚本复合指令
  - 分布式锁
- [ ] redis处理高并发读
  - redis单机读的qps在万级，使用一主多从+哨兵集群，主从复制，读写分离。海量数据可以用cluster模式，多个主分别存储。
- [ ] redis/map对比
  - redis可以用几十G内存来缓存，Map不行
  - redis可以持久化，Map是内存对象
  - redis可以实现分布式缓存，并且可以高并发
  - redis有过期机制，有丰富的API
- [ ] redis stream
  - 适用于消息队列的高级数据结构，之前的list实现比较难重复消费，订阅/发布如果订阅者不在线消息会丢失，stream是一种标准化的消息队列，`XADD qname ID key [value ...]`,`XREAD [count] [block time] STREAMS qname`(可以阻塞或者非阻塞),`XACK`,`XPENDING`(查看未确认消息),支持消费者组，pending列表其实就是做消息备份和转移。

## mysql

- [ ] 数据库三范式
  - 第一范式：列的原子性。第二范式：实体的属性完全依赖于主关键字（不能依赖联合主键的一部分，否则可能会导致数据冗余和更新不便）。第三范式：在任一主键都可以确定所有非主键字段值的情况下，不能存在某非主键A可以获取非主键B
- [ ] **InnoDB和MyISAM的区别**
  - InnoDB支持事务、外键，MyISAM不支持
  - InnoDB按主键聚集，主键索引是聚簇索引，数据和索引绑定在一起，必须要有主键；MyISAM数据和文件是分离的，索引保存数据文件的指针
  - InnoDB不保存表的行数
  - MyISAM采用表级锁，InnoDB支持行级锁和表级锁，默认行级锁
- [ ] 超键、候选键、主键、外键
  - 超键：在关系中能唯一标识元组的属性集；候选键：最小超键，没有冗余；主键：表中唯一和完整标识的数据列或者属性组合，一个数据列只能有一个主键且非空；外键：在一个表中存在的另一个表的主键。
- [ ] sql约束有哪几种
  - 非空、不可重复、主键、外键、控制值的范围
- [ ] varchar和char的区别
  - char是定长字段，varchar申请的是最大长度，占用空间为实际长度+1，最后一个字符存实际空间，在效率上char>varchar。
- [ ] in和exist的区别
  - in把内表和外表做hash链接，exists对外表做loop循环，每次循环对内表进行查询
  - 如果内外表大小相当，则性能相当。否则子查询表大的用exists，子查询表小的用in
  - not in、in不走索引
- [ ] delete、truncate、drop的区别
  - 速度上drop>truncate>>delete
  - delete属于DML语言，其他的是DDL语言
  - delete可回滚、其他不可回滚
  - delete只删除指定数据，表结构还在；truncate删除所有数据；drop删除表
- [ ] 存储过程
  - 存储过程是一些预编译的sql语句，这些语句像一些方法一样实现一些功能，执行效率高，但复用性不高时也不方便。
- [ ] mysql查询执行过程
  1. 客户端通过tcp连接发送连接请求到mysql连接器，连接器对该请求进行权限验证和连接资源分配
  2. 查缓存（任何字符上的不同，比如空格、注释都会导致缓存不命中）
  3. 语法分析（检查语法错误，检查表和列是否存在等）
  4. 优化（是否使用索引，生成执行计划）
  5. 交给执行器，数据保存到结果集，逐步将数据缓存到查询缓存中，结果集返回给客户端
  更新语句还涉及到是否有排他锁、写binlog、刷盘、是否commit等。
- 事务
  - [ ] 数据库事务的定义
    - 一个不可分割的数据库操作序列，其结果使数据库从一种一致性状态变成另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。
  - [ ] **事务的特征**
    - 原子性（要么都做，要么都不做）
    - 一致性必须使数据库从一种一致性状态变成另一种一致性状态(如果只有部分修改成功并且修改写入物理数据库，这时数据库处于一种不正确或者不一致的状态)
    - 隔离性：一个事务不能被其他事务干扰，并发执行的各个事务之间不能互相干扰
    - 持久性：一个事务一旦提交，对数据的改变是永久性的，接下来的其他操作或故障不应该对其结果有任何影响。innodb基于redo log的两阶段提交实现。
  - [ ] **mysql的四种隔离级别**
    - 读未提交：一个事务可以看到其他未提交事务的执行结果；
    - 读已提交：大多数据库系统的默认级别，不可重复读
    - 可重读：mysql默认的级别，同一事务的多个实例并发读数据，会看到同样的数据行，但会有幻读。
      - mysql基于read view实现。(在第一次select的时候获取read view就是可重复读，每次select都获取就是读已提交)
      - mysql通过undo log链来确保只能读到事务id小的更改。mysql在这一级别通过行锁和间隙锁的组合 Next-Key 锁解决了幻读问题。
    - 可串行化：通过强制事务排序，不可能互相冲突，但是会有大量超时和锁竞争。
    - alter table可以更改隔离级别
  - [ ] 脏读、不可重复读、幻读
    - 脏读：事务A读取B更新的数据，然后B回滚，A读到的数据是脏数据
    - 不可重复读：A多次读统一数据，B在A读过程中更新并提交，A多次读结果一致（侧重改）
    - 幻读：A修改所有数据，但B同时插入了一条数据，A改完后发现少改了一条（侧重增删）
  - [ ] 实现
    - 基于重做日志和回滚日志。提交一个事务必须先把所有日志写入重做日志进行持久化，从而确保原子性和持久性，有修改事务时会产生回滚日志，如果需要回滚会根据反向语句进行回滚，确保原子性和一致性。
- [ ] binlog
  - 记录所有数据库表结构变更以及表数据修改的二进制日志，以事件形式记录，还包括执行耗时，mysql的二进制日志是事务安全型的，主要目的是复制和恢复
  - statement基于sql语句的模式，但是某些语句比如uuid可能导致数据不一致；row记录行的变化，但是日志大并且可能提高从库延迟；mix是混合模式，根据语句选用具体模式。
- [ ] 是否可以在事务中混合使用存储引擎
  - 尽量不要。事务由下层存储引擎实现，如果混合使用了非事务型的表，一旦发生回滚会导致非事务型表的数据无法撤销，从而导致事务不一致。
- [ ] **mvcc**
  - 多版本并发控制，通过保存数据在某个时间点的快照实现
  - 实现原理：Innodb聚簇索引记录包括三个隐藏的列，row id(隐藏的自增id)、事务id(记录最后一次修改的事务)、回滚指针(指向这条记录的上一个版本)，这个历史版本存在undo log中。如果要更新，对要修改的行加排他锁然后将原记录放入undo log，接着修改行和事务ID，将回滚指针指向undo log中的原记录，接着提交事务释放锁。
  - 事务启动生成一个数组，保存启动瞬间已经启动但未提交的事务id。如果记录小于低水位可见，大于高水位不可见，在高低水位之间，如果在数组内不可见。只读事务分配假的事务id。
  - 修改时执行当前读，查询一般是快照读。
- 锁
  - [ ] 为什么要加锁
    - 并发的存取数据如果不加控制的话可能会读写不正确的数据，破坏数据库一致性
  - [ ] 按照锁的粒度划分有哪些类型
    - 行级锁：开销大，加锁慢，可能死锁；粒度小，并发度高，冲突概率低（mysql通过索引上的索引项加锁实现，只有通过索引条件检索数据才能使用，否则会使用表锁）
    - 表级锁：实现简单，资源消耗小
    - 页级锁：介于二者之间
  - [ ] 从锁的类别上分MySQL都有哪些锁
    - 共享锁：读锁，要读数据时对数据加共享锁，可以加多个
    - 排他锁：写锁，要写数据是加排他锁，只能加一个，与其他的排他锁或者共享锁都互斥
  - [ ] 乐观锁和悲观锁
    - 乐观锁假定不会冲突，只在提交时检查是否违反数据完整性，修改数据时把事务锁起来，通过version的方式锁定，更新时刚才读到的版本号和当前必须相等，否则重读；适合用在频繁读的场景，如果有大量的写会增加冲突可能性，不断重新获取数据
      > select * from table where id = 1
      > update table set price = 1, version = version + 1 where id = 1 and version = 0
    - 悲观锁假定会冲突，屏蔽一切可能违反数据完整性的操作，查询完就把事务锁起来，直到提交事务。适合大量写入操作的场景，如果大量读，锁的开销太大
  - [ ] 什么是死锁，怎么解决
    - 两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环
    - 互斥条件、请求和保持条件、不剥夺条件、环路等待条件
    - **减少死锁的方法**：
      - 如果不同程序并发存取多个表，尽量约定相同的顺序访问表
      - 同一个事务中尽可能一次锁定所有需要的资源
      - 通过使用更大粒度的锁来减少死锁概率
    - 并发插入导致的死锁
      - 批量插入事务并发，后插入的数据出现到了更前的位置
      - 事务2后启动但先写入，插入成功后获取排他锁；事务1要插入，由于唯一索引冲突，转为获取next-key锁(共享锁+间隙锁)。因为事务2持有排他锁，所以共享锁等待，但是可以正常获取间隙锁，锁住上一条记录到该记录的区间。事务2写入之前要获取插入意向锁，这也是一种间隙锁，要等待事务1释放。
      - 可以降低事务隔离级别；避免并发；插入语句事先排序；逐条插入；或者ignore、on duplicate关键字避免唯一键冲突
      - 还有说三个插入相同主键，事务1插入后回滚，事务2、3一个插入成功，一个死锁。（回滚后可以插入，都持有共享锁去获取排他锁。一个死锁错误后释放，另一个成功）
  - [ ] 隔离级别和锁的关系
    - 读未提交：读数据不加锁
    - 读已提交：读数据加共享锁，语句执行完释放
    - 可重复读：读数据加共享锁，事务提交后释放
    - 可序列化：锁定整个范围的键并一致持有到事务完成
  - [ ] 优化锁
    - 使用较低的隔离级别
    - 设计索引，尽量使用索引访问数据，加锁更精确
    - 选择合理的事务大小，一次性请求足够级别的锁
    - 不同程序访问一组表时尽量约定相同的顺序来访问表，对于一张表尽量用固定顺序访问表中的行，减少死锁
    - 尽量使用相等条件访问数据，避免间隙锁对并发插入的影响
    - 不要申请超过需要的锁级别
    - 查询不必要的时候不加锁
    - 特定的事务申请表锁来避免死锁
  - [ ] 实现接口的幂等
    - 分布式的话，程序加分布式锁或者数据库加悲观锁(for update)/乐观锁/借助唯一性约束确保只有一个插入成功
- 索引
  - 索引是一种特殊的文件，包含对数据表里所有记录的引用指针
  - [ ] **优缺点**
    - 大大加快数据检索速度(索引可以通过事先的排序来二分查找提高效率)，提高查询读取性能；创建和维护要消耗时间和物理空间，降低写入性能。
    - 表记录少、经常增删改不适合创建索引，大数据类型的字段不适合用来创建索引，某列包含很多重复数据也最好不要对这列创建索引
  - [ ] mysql的索引类型：
    - 存储形式：BTree索引、B+Tree索引、Hash索引、full-index全文索引、R-Tree索引
    - 应用层次：
      - 普通索引：一个索引只包含单个列，一个表可以有多个单列索引
      - 唯一索引：索引的值必须唯一但可以为空。用关键字UNIQUE定义成唯一索引后如果有新数据插入，会自动检查字段值是否已出现过，如果是会拒绝插入。
      - 复合索引：多列值组成一个索引用于组合搜索
      - 聚簇索引：并不是单独的索引类型，而是存储方式，Innodb就是在一个结构中保存了B+Tree索引和数据行
      - 非聚簇索引
    - 根据物理顺序和键值的关系：聚集索引、非聚集索引
  - [ ] **为什么索引默认使用B+树**
    - 相比B树
      - B+树磁盘读写代价更低：树内部节点没有指向关键字具体信息的指针，节点更小，一次性读入内存的待查关键字更多，I/O次数低
      - 区间查询更方便，直接扫一遍叶子节点即可
    - hash
      - 可以快速定位但是没有顺序，I/O复杂度高
      - 不支持范围查询
      - 不能利用索引排序
      - 有大量重复键的时候存在哈希碰撞问题，效率低
    - 红黑树：高度随数据量增加，I/O代价高
    - B+树磁盘I/O次数与高度相同，一般不会超过3层，非叶子节点存放指针，最小存储单位页的默认大小是16KB，存索引假设可以存1k个，3层就可以区分出百万级的叶子节点。
  - [ ] B+ 新增删除节点
    - 新增：找到第一个大于key的位置，如果键的数量少于最大数量，直接插入；否则从中间拆成两个部分，中间的key插入父节点，如果父节点的数量大于最大值，也需要拆分，非叶子节点key上升父节点会将原来的key删除
    - 删除：找到叶子节点，如果删除key后不小于ceil(max/2)则满足要求(如果key在父节点也要调整)，否则向左右兄弟去借key，并且修改父节点。如果左右都没条件借，合并到其中一个兄弟节点。调整父节点的值然后判断父节点是否满足条件。
  - [ ] 聚簇索引与非聚簇索引
    - 聚簇索引的叶子节点存整行数据，非聚簇索引存主键的值
    - 通常主键（聚簇）索引只查一次，非聚簇索引需要回表多次（覆盖索引不需要回表），回表是随机I/O，次数越多越倾向于全表扫描
  - [ ] **联合索引**
    - 可以使用多个字段同时建立一个索引，叫做联合索引
    - 适合多列条件的筛选，使用覆盖索引可以减少回表，列的顺序重要，索引的大小增加。
    - 如果想要命中索引，需要按照建立时的字段顺序挨个使用，因为mysql要求索引有序，索引会按照建立的顺序进行排序。一般热点字段放前面
    - 最左前缀原则
      - where字句中最频繁的一列放在最左边，mysql一直向右匹配到范围查询就停止匹配。=和in可以乱序。
      - 对(a,b,c,d)建立索引
        - a=1；a=1 and b=2;b=2 and a=1;b>1 and a=2; 可以用到索引
        - b=1；不可以。a=1 and b=2 and c>3 and d=4 前三个字段可以
  - [ ] 覆盖索引
    - 将查询sql中的字段都放在联合索引里，可以减少回表次数。由于必须要存索引列的值，mysql只能用b-tree做覆盖查询
    - 有count、orderby或者列查询优化（比如select name,sex where name=' white'）比较适合覆盖索引
  - [ ] 前缀索引
    - 只要把很长字段前面的公共部分作为一个索引即可，但是order by不支持前缀索引
  <!-- - [ ] 索引下推 -->
  - [ ] 查询是否用到索引
    - explain关键字，通过type判断级别，通过possible_keys看查询时用到的索引，通过key看实际决定查询结果时使用的索引
  - [ ] 为什么建议使用自增长主键作为索引
    - 结合B+树特点，自增主键是连续的，再插入过程中尽量减少页分裂，并减少数据的移动，每次都插入到最后
  - [ ] 创建索引的方式
    - create table时；alter table；create index
  - [ ] **建索引的原则**
    - 最左前缀匹配原则
    - 尽量选择区分度高度列作为索引
    - 索引列不要参与计算
    - 尽量扩展索引而不是新建索引
  - [ ] 索引查询是否一定能提高性能
    - 不一定，索引需要存储和维护；索引范围查询适合两种情况：基于范围的检索；基于非唯一性索引的检索
  - [ ] 索引失效的情况
    - 使用!=,<>；类型不一致导致的索引失效；函数/运算符导致的索引失效；OR连接不同字段；模糊搜索；not in、not exists
- [ ] buffer pool
  - 缓存了磁盘数据，磁盘随机读写特别慢，增删改尽量只更新内存然后往磁盘写日志文件，
- [ ] 分库分表
  - 原因
    - 单表数据量比较大（500w行）的时候，性能会下降，可以将一个表中的数据按一定规则拆分成多个表，将每个表的数据控制在一定范围内
    - 如果并发数比较大（2000并发），可以将一个库的数据拆分到多个
  - 水平拆分和垂直拆分
    - 水平拆分：把一个表的数据放到多个库多个表，表结构都一样，可以用多个库来抗高并发和扩容
    - 垂直拆分：扒一个很多字段的表拆分到多个表或者多个库，热点字段放一个表，其他放在别的表里，可以缓存更多的行。
  - 方式
    - 一种是按范围来分，每个库一段连续数据，比如按时间分表，但是热点可能都在最新的数据上
    - 另一种是按某个字段hash均匀分散，可以分配每个库的数据量和压力，但是扩容麻烦，之前的数据需要重新计算hash然后迁移
  - 分库分表后连接查询
    - 利用union，union all
    - 建中间表、全局表、冗余字段
    - 利用缓存
    - 多线程处理各个分表
- [ ] 高并发读写，设计上有哪些可用方案
  - 分库分表、主从同步、读写分离
- 主从
  - [ ] 主从同步的目的
    - 增加从服务器提高性能，在主服务器写入和更新，在从服务器读。
    - 提高数据安全，从服务器可以做备份
    - 在主服务器生成实时数据，在从服务器分析，可以提高主服务器性能
  - [ ] **原理**
    - master在每个事务更新数据完成之前，将该操作记录串行地写入binlog，slave开启一个io线程拉取master的binlog内容，放进relay log，接着顺序执行relay log的事件。
  - [ ] 延时解决
    - 半同步复制：master写入binlog之后强制此时立刻将数据同步到slave，slave写入自己的本地relay log之后返回一个ack给master，master接到至少一个slave的ack之后才认为写操作完成。可以解决主库丢失。
    - 并行复制：slave开启多个线程并行读取relaylog不同库的日志然后并行重放。库级别的并行降低延时
- 优化
  - [ ] sql性能问题定位及优化
    - explain查看执行计划
    - **最大化利用索引、尽可能避免全表扫描、减少无效数据查询**
    - 避免select *，多表关联查询时小表在前，调整where语句的连接顺序（过滤多的条件放前面），避免出现结果不确定的函数，用变量获取更新避免重复访问数据表
  - [ ] 大表数据查询
    - 优化sql语句和索引
    - 加缓存，比如redis
    - 主从复制，读写分离
    - 分库分表
  - [ ] 超大分页处理
    - `select * from table where age > 20 limit 1000000,10` 并不是跳过100w取n行，而是取100w+n行，改成快速定位id再关联`SELECT a.* FROM table a, (select id from table where age > 20 LIMIT 100000,10 ) b where a.id=b.id`
    - 使用缓存
  - [ ] 关联查询优化
    - 确定ON或者USING中是否有索引
    - 确保GROUP BY和ORDER BY只有一个表中的列，否则不用索引
  - [ ] 慢查询优化
    - 是否查询了额外的数据、是否索引失效、是否数据量太大需要分表
  - [ ] 数据库结构优化
    - 字段多的表拆分；经常联合查询的可以考虑使用中间表；必要时可以使用冗余字段减少连接查询（但是修改时需要在所有表更新）
  - [ ] cpu占用飙升怎么处理
    - show processlist，查看session情况，找出消耗高的sql，看执行计划是否准确，还是因为数据量的问题，也有可能每个sql消耗不高但是连接数激增导致cpu占用高
    - 一般kill掉这些消耗高的线程进行调整后重跑
- 日志
  - [ ] 日志类型
    - 错误日志、查询日志、慢查询日志、事务日志、二进制日志(bin log)、中继日志
  - [ ] 为什么有binlog还要redo log
    - binlog记录所有与mysql数据库有关的日志记录，redo log只记录innodb本身的日志
    - binlog记录的是一个事务的具体操作内容，是逻辑日志；redo log记录的是每个页的更改的物理情况
    - binlog只在事务提交前提交，只写一次。redo log在执行过程中会不停的写入
  - [ ] **执行顺序**
    - 开启事务，将记录加载到buffer pool，修改前记录undo log。更新记录，修改记录到redo log中，更新完成执行器写binlog，接着二阶段提交redo log
    - 如果不用两阶段提交，假如先写redo log并且写完后崩溃，如果用binlog来恢复临时库，就会少一次更新；假如先写bin log，如果写完崩溃，该事务其实无效，但是binlog恢复会多一个事务出来。如果使用两阶段，binlog后崩溃，先检查redo log是否存在且完整，两个日志逻辑是否一致，如果有问题就回滚日志。
  - [ ] WAL 预写日志
    - 先把日志写入log buffer，后续某个时间点再一次性将多个操作记录写到log file。
- sql语句
  - 可以用gorm.raw()执行原生sql
  - 有一张表有学生、班级、性别等字段，如何通过一条SQL语句查出各班级分别有多少男生
    `SELECT class, COUNT(CASE WHEN gender='boy' THEN 1 ELSE NULL END)AS male_count FROM students GROUP BY class`
  - 每个班成绩前5的学生
    `SELECT id,class,score FROM sc s where (SELECT count(case WHEN class=s.class AND score>=s.score THEN 1 ELSE NULL END) FROM sc)<=5`
  - 返回content大于15的id(CHAR_LENGTH返回字符串的长度，LENGTH返回字节数，某些特殊字符可能多于一个字节)
    `SELECT tweet_id FROM Tweets WHERE CHAR_LENGTH(content)>15`
  - mysql使用三值逻辑，
    - TRUE OR NULL=TRUE，FALSE AND NULL 结果为 FALSE
    - FALSE OR NULL 结果为 NULL，TRUE AND NULL 结果为 NULL，NOT NULL 结果为 NULL，NULL XOR TRUE/FALSE/NULL 结果为 NULL，NULL = NULL 结果为 NULL
    - IS NULL 是唯一可以将NULL转换为逻辑真假的运算符
  - datediff(a,b)返回a-b的天数
  - mysql between ... and ... 包括边界值
  - select count(1) from t 统计行数，不想统计的count里if成null，sum里if成0
  - select里的字段可以拿来聚集，比如select DATE_FORMAT(trans_date, "%Y-%m") AS month FROM C GROUP BY month,date_format(date, "%Y-%m")更改日期格式

## 网络

- [ ] **OSI七层模型和TCP五层模型**
  - OSI
    - 应用层：为应用程序提供网络服务
    - 表示层：数据格式转换、数据压缩、加密
    - 会话层：建立、断开和维护通信连接
    - 传输层：为上层协议提供端到端的可靠传输
    - 网络层：寻址和路由
    - 数据链路层：定义通过通信媒介互连的设备之间传输的规范
    - 物理层：利用物理传输介质为数据链路层提供物理连接
  - TCP：把应用层表示层会话层都合并为应用层
- [ ] 面向有连接型和面向无连接型
  - 面向有连接型传输包括会话建立、传输数据和会话断开，此外还包括传输可靠性的各种措施，比如超时重传、流量控制等，比如TCP
  - 面向无连接型传输仅提供基本的数据传输功能，即使接收端不存在，也能发送数据包，常见的有UDP、IP
- [ ] TCP UDP区别
  - TCP是面向连接型的，UDP是面向无连接型
  - TCP是一对一传输，UDP支持一对一、一对多、多对一、多对多的交互通信
  - TCP把上层的报文看成字节流，拆分成大小不等的数据块，并添加TCP首部；UDP既不拆分也不合并，仅添加UDP首部
  - TCP支持传输可靠性的多种举措，包括保证传输顺序、重发机制、流量控制和拥塞控制，UDP仅提供基本的数据传输能力
  - UDP速度快，无需连接建立，不需要维护连接状态，首部开销小
- [ ] TCP UDP对应的应用层协议
  - TCP：FTP、HTTP、SSH
  - UDP：DNS、TFTP、SNMP
- [ ] **三次握手、四次挥手**
  - 三次握手
    - 客户端发送一个带SYN标志的报文到服务器
    - 服务器回客户端一个报文，带有SYN+ACK标志
    - 客户端再回一个ACK报文
    - 三次可以阻止重复历史连接的初始化，比如有个请求直到连接释放后才到达，服务端回ack后如果不经确认就建立好了连接，将不会有数据发过来。
  - 四次挥手
    - 客户端发送一个FIN用来关闭客户端到服务器的数据传送，客户端变为FIN_WAIT_1
    - 服务器收到后发回一个ACK，服务端变成CLOSE_WAIT，客户端收到后变成FIN_WAIT_2
    - 服务器关闭客户端的连接，发送一个FIN给客户端，服务端变成LAST_ACK
    - 客户端发回ACK并确认，客户端收到后变成TIME_WAIT
  - 为什么关闭和建立次数不同：服务端收到FIN只能代表客户端不再需要发送数据，服务端自己可能还有一些数据要发送。
  - TIME_WAIT原因：客户端发送给服务端回执后，有可能这个回执报文在传输途中丢失等原因，服务端并没有收到，此时服务端会再次向客户端发送断开请求报文，如果客户端不等待2*MSL直接CLOSED会导致服务端无法进入CLOSED，或者有可能被新的连接接收到
- [ ] TCP 半连接/半关闭/半打开
  - 第二次握手后，socket会放入半连接队列，第三次握手后将socket移出到全连接队列。
  - 第二次挥手后，请求关闭的一方不能发送数据，但仍可以接受数据。
  - 半打开：一方异常关闭后，另一方并不知情。只有通信时才能察觉到半打开状态，可以引入心跳机制。
  - 半连接队列和全连接队列都有长度限制，半连接队列满了可以丢弃（相当于调用失败，可以感知）也可以开启syncookie。全连接队列溢出后直接丢弃，可以配置策略是否通知client（不配置的话无法感知，因为连接已经建立了）。
  - 增大半连接队列，使用syncookie，减少第二次握手的重试次数（超过次数断开）可以防御SYN攻击。
- [ ] TCP如何保证可靠性
  - 校验和
  - 序列号与确认应答
  - 重传机制
  - 流量控制和拥塞控制
- [ ] ARQ协议
  - 自动重传请求，如果发送后一段时间没有收到确认回执，通常会重新发送
  - 停止等待ARQ：如果接收方没有回ACK，发送方重新发送，并且维护一个超时计时器，超时事件会比数据往返传输的事件长一些。
  - 连续ARQ：维护一个窗口，窗口内有多个分组，窗口内的分组可以连续发送而不等待ACK，对按序到达的最后一个分组，接收方发送ACK，然后该序号后的分组会重新发送给接收端。可以提高信道利用率。
- [ ] TCP流量控制
  - 控制发送端发送端速率，接收端会告知自己所能接收的数据大小，发送端不会发送超过这个数据量的数据，这个大小称为窗口
- [ ] TCP拥塞控制
  - 如果在通信开始时立即把大量的数据注入网络，可能引起网络阻塞，常见的策略有：慢启动、快重传与快恢复
  - 慢启动：通信开始时定义一个拥塞窗口，窗口大小为1，每收到一个ack就增大拥塞窗口，发送端发送时选择拥塞窗口和流量控制窗口的最小值(可能以更小的数据量进行发送)。
  - 快重传：如果收到了失序报文，及时发送对最后一个有序报文段的确认，如果发送方连续收到三个重复确认，就应当立即重传未收到的报文段。因为这个时候大概率没有发生拥塞，发送方只把慢开始门限减半，然后再加法增大
  - 判断：看是否有丢包、ack确认的延迟、拥塞窗口的大小以及根据收到的重复确认判断。
- [ ] TCP粘包
  - 如果客户端连续不断发送数据包，服务端接收的数据可能会出现两个数据包粘在一起的情况。因为TCP是基于字节流的，也没有表示数据长度的字段
  - 如果发送的数据过小，默认会把数据包合并发送，这时会粘包；接收方会把数据放置在接收缓冲区，如果应用层不能及时的读取，下一个数据到来会有一部分放入缓冲区末尾，导致粘包
  - 可以在包尾加上特殊字符或者报文首部加上包的长度防止粘包。
- [ ] URI和URL的区别
  - URI是统一资源标识符，唯一标识一份资源。URL是统一资源定位符，是URI的子集。
- http
  - [ ] http是无状态协议，怎么解决
    - 协议自身不对请求和响应之间的通信状态做保存，对请求和响应都不做持久化处理，这样可以更快的处理大量事务
    - 引入cookie状态管理。在请求和响应报文中写入cookie信息来控制客户端的状态。客户端会根据服务端响应报文的set-cookie字段保存cookie，下次发送请求时自动在请求报文中加入cookie值发送出去，服务端收到后检查是哪一个客户端并对比服务器上的记录，得到之前的状态信息。
  - [ ] 常见的http动词
    - 安全方法
      - GET：从服务器获取资源
      - HEAD：获取资源的元数据
    - 不安全方法
      - POST：在服务器新建资源
      - PUT：在服务器更新资源
      - DELETE：删除资源
    - OPTIONAL：查询对指定资源支持的方法
  - [ ] GET和POST的区别
    - post一般用于修改和写入数据；get用于获取资源读取数据
    - get把参数包在url，post放在body，也因此post更安全，不会作为url的一部分被保存
    - get请求更快：post会先把请求头发给服务器进行确认，然后才真正发送数据；get会缓存，post不会
    - post能发送更大的数据和更多的数据类型
  - [ ] 常见状态码
    - 1** 收到请求，需要请求者继续执行操作
      - 100 继续；101 切换协议
    - 2** 成功接收并处理
      - 200 成功；201 已创建；202 已接受但未处理完成
    - 3** 重定向
      - 300 资源包括多个位置以供选择；301 永久移动
    - 4** 客户端错误，请求语法错误或者无法完成
      - 400 语法错误无法理解；401 要求身份认证；403 理解但拒绝执行；404 无法找到
    - 5** 服务器错误，在处理过程中发生错误
      - 500 服务器内部错误; 502 错误的网关；504 网关超时。
  - [ ] 各个版本的区别
    - 1.0 无状态，无连接（每次建立一个tcp连接，完成后立即断开），可以接触cookie/session来做认证和记录。连接无法复用
    - 1.1 长连接提高了利用率；管道化，能同时发送多个请求，服务器按照先后顺序依次回送；缓存处理机制；断点续传
    - 2.0 在应用层和传输层之间增加二进制分层帧，改进传输性能。多路复用，头部压缩。服务器还可以额外向客户端推送资源，而无需客户端明确的需求。
    - 3.0 基于udp，丢包只需要重发丢失的包即可。基于id而非ip识别，移动端的表现更好。报文头部加密，安全性好。向前纠错机制，数据包除了本身还包括其他数据包的数据，少量丢包可以通过冗余数据组装，不用重传。
- https
  - [ ] http和https的区别
    - http全称是超文本传输协议，客户端和服务端通信时将信息以http报文的形式传输
    - 可以简单认为https=http+加密+认证+完整性保护
    - http通信使用明文，可能被窃听；通信双方的身份无法得到认证；无法验证报文的完整性
  - [ ] **https过程**
    1. 客户端发起一个请求，告诉服务器自己支持的加密套件和一个随机数N1
    2. 服务器响应请求信息以及选择的加密套件和一个随机数N2
    3. 服务器向客户端发送证书，包括公钥和签名
    4. 客户端验证证书的合法性并生成一个预主密钥，然后根据证书中的公钥对其加密；根据两个随机数和客户端生成的预主密钥生成主密钥；发送预主密钥给服务端
    5. 服务端用私钥解密预密钥（私钥没被发送过，只要私钥不泄露就是安全的）
    6. 客户端发送change cipher spec，告诉服务端后续将切换到加密后再传输；服务端根据两个随机数和预主密钥生成主密钥，也回一个类似的响应。
- iptables/netfilter
  - iptables是一个包过滤防火墙，netfilter时linux内核协议栈中的一套防火墙系统
- [ ] **浏览器输入网址发生了什么**
  - 浏览器查找IP地址，dns过程如下
    1. 查找浏览器缓存，查找成功返回否则下一步
    2. 查找系统缓存，看本机hosts文件，查找成功返回否则下一步
    3. 查路由器缓存，一般路由器都有自己的dns缓存，查找成功返回否则下一步
    4. 递归查询：查首选dns服务器缓存，如果没有的话，它会将请求转发到根域名服务器，而不是让该主机自己进行下一步查询。
    5. 迭代查询：本地服务器查询根域名服务器，根域名服务器收到查询请求后，告诉本地服务器下一步查询哪个域名服务器，然后进行后续查询，后续也是如此直到找到ip。
  - 浏览器与目标服务器建立tcp连接
  - 浏览器给web服务器发送http请求，这里一般是get
  - 某些服务器会做重定向，浏览器找到重定向地址，重新第一步访问。重定向是为了负载均衡或者导入流量，关联两个网站在一起可以提高搜索排名
  - 服务器处理请求并返回响应，比如一个html
  - 释放http连接
  - 浏览器显示页面，根据html做渲染，没有接收完时就已经开始显示页面了。
  - 有些样式文件可能要重新发送请求。
- [ ] http/tcp keepalive
  - tcp keepalive 默认是关闭的，tcp的任何一方都可以打开此功能，如果一段时间不活跃，开启保活功能的一端会向对端发送一个保活探测报文，如果回复了就重置保活计数器，如果一段时间没有就继续发送，直到达到上限后认为不可达断开连接。
  - http keepalive 1.0默认关闭，1.1默认开启。响应后不再直接断开tcp连接，而是维持一段时间。如果再次发起可以复用此tcp连接，并重置时间计数器。降低反复创建和销毁的开销。
- [ ] 数据包路由过程
  1. 在A主机封装，应用层上发出一个数据包，传给传输层，分成数据段，在网络层加上ip包头，包括源和目的ip等，在数据链路层进行帧的封装，加上帧头和尾的校验码，包括了源mac地址和目的mac地址等，如果不在一个网段，把数据帧发给默认网关。
  2. 路由器接收数据后，放在接口里校验，拆掉数据帧的封装取出数据包，在路由表中寻找网段，重新封装，源mac是自己，目的mac是下一跳。
  3. 一直到主机接收，主机核对目的mac地址和自己是否一致，否则丢弃；检查帧尾的校验，损坏丢弃；拆除封装传给网络层；网络层核对目的ip后拆掉ip包头；传输层按顺序重组成数据流。

## mq

[rabbitmq](./done/rabbitmq.md)

- [ ] 引入消息队列的优缺点
  - 解耦；异步提升效率；削峰填谷
  - 中间件的可用性会影响系统可用性；复杂性提高；一致性问题
- [ ] rabbitmq与kafka对比
  - kafka适合高吞吐和低延迟场景，rabbitmq支持消息少和可靠性要求高的场景
  - rabbimq用磁盘存储消息，kafka将消息存在内存日志，可能会丢数据
- [ ] 怎么做幂等
  - 根据消息生成唯一id+业务指纹码，利用数据库主键去重
  - 利用redis的原子性命令，比如setnx
- [ ] kafka消费组
  - 每个消费者都有一个对应的消费组，发布到主题后，只会投递个每个消费组中的一个消费者。所有消费者都属于一个消费组相当于点对点，所有消费者都属于不同消费组相当于广播。
- [ ] 推和拉对比
  - 推将消息提前推送给消费者，消息者需要设置一个缓冲区储存消息。消息到达后立刻投递给匹配的消费者，实时性好
  - 需要时才去拉取消息，增加消息延迟
  - 在循环中拉取会影响性能，高吞吐量需要同推模式

## etcd

- lease
  - 检测客户端存活状态的机制，群集授予有生存时间的租约，如果给定时间未收到keepalive则租约到期
  - 可以把key绑在租约上，租约到期或被撤销时，附的所有key都被删除。
- watch
  - 监听一个或一组key，任何变化都会发出消息
  - 在store上封装一层watchableStore，任何写操作都要经过。收到了所有 key 的变更后，将这些 key 交给 synced（watchGroup），synced 能够快速地从所有 key 中找到监听的 key（map+红黑树，红黑树可以用来找范围）。将这些 key 发送给对应的 watcher，这些 watcher 再通过 chan 将变更信息发送出去。

## gin

- [ ] 路由数据结构怎么实现的
  - 采用前缀树（基数树，对前缀树的单节点进行了合并）的方式实现动态路由。前缀树能利用字符串的公共前缀减少查找时间，最大限度的减少不必要的字符比较。
  - 官方net包采用路由表map实现，功能有限，不能对路由分组，不能限定路由的请求方法，不能对路由加中间件。
  - 也有基于正则的实现。

## 容器

- [ ] 程序怎么部署的
  - 写dockerfile，golang一般可以基于golang最新版本为基础镜像，使用alpine可以减少镜像的大小
  - 根据dockerfile创建项目镜像，build -t
  - 基于项目镜像创建并运行容器, docker run
<!-- - [ ] kubernetes核心组件和功能？
- [ ] 如何监控kubernetes和部署在之上的服务？这些指标是怎么采集出来的？
- [ ] 采集哪些数据和指标？使用推的方式还是拉的方式？
- [ ] 提供的指标的服务是通过什么实现的？ 面试官说metrics server
- [ ] 除了 pod 和 deployment的监控指标还有一些其他的指标吗？
- [ ] 有没有相关web服务指标的采集？（http请求量，相应时间，错误率），有采集端APM(未涉及) -->

## 场景题

- 建模：地震了，牛羊骡马不进圈，猪不吃食狗乱咬，鸭不下水岸上闹，大鼠叼着小鼠跑。
  - 提示是观察者模式
- 两个文件里有几亿个ip，（内存较小）完成对比。
  - 感觉应该是hmap
- 微信群里10个人，发8元红包，让9个人抢。
  - 钱怎么划分
- 海量文本去重
  - 先分词然后计算出simhash，得到一个64位二进制数。查询就是，比如有100亿(2^34)个文章的simhash，给定一个新的判断是否与已有的相似。假设阈值为3，将simhash拆成4段，根据抽屉原理，两个相似的simhash至少有一段完全相同，把4段分别作为key，自身作为value。一个新的simhash要在4个set里分别去重，每个set约有2^34/2^16个元素。
  - 本质上是冗余4份，牺牲空间换时间。
  - simhash，将长文本压缩至几个关键词再编码成一个二进制字符串代表一篇文章。先去停用词，计算每个词的tf-idf得分，接着对得分比较大的n个关键词编码，相应位置是1的权重取正否则取负，这些词列项累加，然后负数取0正数取1，用汉明距离衡量相似度，通常阈值是3。
<!-- - 怎么判断淘宝刷单 -->
<!-- - 怎么把一个文件快速下发到100个服务器 -->
